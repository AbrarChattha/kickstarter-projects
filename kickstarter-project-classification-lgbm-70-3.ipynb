{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3be2f0dad24b2154cb80c493aba7841e6c447ade"
   },
   "source": [
    "# Problem Statement\n",
    "To predict if a kickstarter project will be successful or will fail before its actual deadline. Also identify the factors that determine the success rate of a project.\n",
    "\n",
    "\n",
    "# Solution Notebook\n",
    "This notebook basically has 4 steps/ modules:\n",
    "    1. Data Understanding (EDA) and Preprocessing\n",
    "    2. Feature Engineering and heuristic feature selection\n",
    "    3. Model Building\n",
    "        3A. XGBoost\n",
    "        3B. Random Forest\n",
    "        3C. LGBM (2 versions: with one-hot encoded features and with categorical features at integer-category columns)\n",
    "        3D. Ensemble Models- ormal Averaging and AdaBoosting\n",
    "    4. Feature importance\n",
    "    \n",
    "The best accuracy obtained was 70.3% accuracy on Test Data from LGBM (version 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "88095ebec76619f69af5aa3f6fb43493b745e543"
   },
   "source": [
    "## Setting up the requires libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ccd53887439ec5be5b7c5e03869463e08332af4f"
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import string\n",
    "#import itertools\n",
    "#from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa4d43fc06b54ea69d82e17f14af4e7a4bc4cef2"
   },
   "outputs": [],
   "source": [
    "#setting working directory\n",
    "#os.chdir(\"/home/srishti/Srishti Saha- backup/misc/personal/kickstarter_projects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5a9340428ee763c20d58fe025340e1486eb4383"
   },
   "source": [
    "## Importing a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9042e9b10d782de3b1eec47778bc45b88443765a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "kickstarters_2017 = pd.read_csv(\"../input/ks-projects-201801.csv\")\n",
    "kickstarters_2017.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d277e06f443a117a9d95bdbd8334ae2a1b3146f"
   },
   "source": [
    "## Basic Tests and EDA on input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4d448315585243cb96da92b94252f00c09cf8fd"
   },
   "outputs": [],
   "source": [
    "#printing all summary of the kickstarter data\n",
    "#this will give the dimensions of data set : (rows, columns)\n",
    "print(kickstarters_2017.shape)\n",
    "#columns and data types\n",
    "print(kickstarters_2017.info())\n",
    "#basic stats of columns\n",
    "print(kickstarters_2017.describe())\n",
    "#number of unique values in all columns\n",
    "print(kickstarters_2017.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f4d64072828c950f732e85f18d7fc298d6963842"
   },
   "source": [
    "The above stats help us reaching the following conclusions:\n",
    "1. the data is at ID level (unique of ID=number of rows)\n",
    "2. The numerical data fields are: goal, pledged, backers, usd_pledged, usd_pledged_real,usd_goal_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d0e295c1922ebcd2d199011823adda5f24452214"
   },
   "source": [
    "#### Understanding Variables in the Dataset\n",
    "\n",
    "The dataset has 15 variablesincluding ID. SInce ID is the level of the dataset, we can set it as the index of the ata later. Variables like name, currency, deadline, launched date and country as self explanatory. Explanations of some key variables are as follows:\n",
    "\n",
    "Main_Category: There are 15 main categories for the project. These main categories broadly classify projects based on topic and genre they belong to.\n",
    "\n",
    "Category: Main Categories are further sub divided in categories to give more general idea of the project. For example, Main Category “Technology” has 15 categories like Gadgets, Web, Apps, Software etc. There are 159 total categories.\n",
    "\n",
    "Goal: This is the goal amount which the company need to raise to start its project. The goal amount is important variable for company as if it is too high, the project may fail to raise that amount of money and be unsuccessful. If it is too low, then it may reach its goal soon and backers may not be interested to pledge more.\n",
    "\n",
    "Pledged: This is amount raised by the company through its backers. On Kickstarter, if total amount pledged is lower than goal, then the project is unsuccessful and the start-up company doesn’t receive any fund. If pledged amount is more than the goal, the company is considered successful. The variable “usd pledged” is amount of money raised in US dollars.\n",
    "\n",
    "Number of Backers: These are number of people who have supported the project by pledging some amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8b3c98d9942b42b4859bdcd4778386900feb5332"
   },
   "outputs": [],
   "source": [
    "#Distribution of data across state\n",
    "percent_success = round(kickstarters_2017[\"state\"].value_counts() / len(kickstarters_2017[\"state\"]) * 100,2)\n",
    "\n",
    "print(\"State Percent: \")\n",
    "print(percent_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "847bb001f7c678933dbf9918aa07c456eb464f3a"
   },
   "outputs": [],
   "source": [
    "#renaming column usd_pledged as there is no '_' in the actual dataset variable name\n",
    "col_names_prev=list(kickstarters_2017)\n",
    "col_names_new= ['ID',\n",
    " 'name',\n",
    " 'category',\n",
    " 'main_category',\n",
    " 'currency',\n",
    " 'deadline',\n",
    " 'goal',\n",
    " 'launched',\n",
    " 'pledged',\n",
    " 'state',\n",
    " 'backers',\n",
    " 'country',\n",
    " 'usd_pledged',\n",
    " 'usd_pledged_real',\n",
    " 'usd_goal_real']\n",
    "kickstarters_2017.columns= col_names_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f1b390374c1cdd97917f12c65a103db24bf838d"
   },
   "outputs": [],
   "source": [
    "#segregating the variables as categorical and constinuous\n",
    "cat_vars=[ 'category', 'main_category', 'currency','country']\n",
    "cont_vars=['goal', 'pledged', 'backers','usd_pledged','usd_pledged_real','usd_goal_real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7b789a30e3d2d37d7a82782afde60fa26ef1e5cd"
   },
   "outputs": [],
   "source": [
    "#correlation of continuous variables\n",
    "kickstarters_2017[cont_vars].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af49ce4663badd844da0839021a3ec6a8cfee0d6"
   },
   "outputs": [],
   "source": [
    "#setting unique ID as index of the table\n",
    "#this is because the ID column will not be used in the algorithm. yet it is needed to identify the project\n",
    "df_kick= kickstarters_2017.set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa5cb9212551027ac6bbe724b11c36c37352b334"
   },
   "outputs": [],
   "source": [
    "# Filtering only for successful and failed projects\n",
    "kick_projects = df_kick[(df_kick['state'] == 'failed') | (df_kick['state'] == 'successful')]\n",
    "#converting 'successful' state to 1 and failed to 0\n",
    "kick_projects['state'] = (kick_projects['state'] =='successful').astype(int)\n",
    "print(kick_projects.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e0cfc679097619e4515512ad7a49a4a9a8ebe947"
   },
   "outputs": [],
   "source": [
    "#checking distribution of projects across various main categories\n",
    "kick_projects.groupby(['main_category','state']).size()\n",
    "#kick_projects.groupby(['category','state']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eceeeb02ed0a0276279ca5f19434c36f20ec0176",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#correlation of continuous variables with the dependent variable\n",
    "kick_projects[['goal', 'pledged', 'backers','usd_pledged','usd_pledged_real','usd_goal_real','state']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "894d8083a1527cf5b43dc4e0dedfc0150f4ef55c"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51cc44af7296d68ce3cc012d280d228d6e52e12f"
   },
   "outputs": [],
   "source": [
    "#creating derived metrics/ features\n",
    "\n",
    "#converting the date columns from string to date format\n",
    "#will use it to derive the duration of the project\n",
    "kick_projects['launched_date'] = pd.to_datetime(kick_projects['launched'], format='%Y-%m-%d %H:%M:%S')\n",
    "kick_projects['deadline_date'] = pd.to_datetime(kick_projects['deadline'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3bf27a43462e2b1bdb4e4e3f3d48da088f53b763"
   },
   "outputs": [],
   "source": [
    "kick_projects= kick_projects.sort_values('launched_date',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "106abd8d6e2fda9bff7cf5d8ed1ee28f1f833362",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kick_projects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1011e2c0295eb372eed17d6d6f378e7ddc28389d"
   },
   "outputs": [],
   "source": [
    "#creating features from the project name\n",
    "\n",
    "#length of name\n",
    "kick_projects['name_len'] = kick_projects.name.str.len()\n",
    "\n",
    "# presence of !\n",
    "kick_projects['name_exclaim'] = (kick_projects.name.str[-1] == '!').astype(int)\n",
    "\n",
    "# presence of !\n",
    "kick_projects['name_question'] = (kick_projects.name.str[-1] == '?').astype(int)\n",
    "\n",
    "# number of words in the name\n",
    "kick_projects['name_words'] = kick_projects.name.apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "# if name is uppercase\n",
    "kick_projects['name_is_upper'] = kick_projects.name.str.isupper().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf491e3e550530dcdf506ef1663d5abb3adbd3b9"
   },
   "outputs": [],
   "source": [
    "# normalizing goal by applying log\n",
    "kick_projects['goal_log'] = np.log1p(kick_projects.goal)\n",
    "#creating goal features to check what range goal lies in\n",
    "kick_projects['Goal_10'] = kick_projects.goal.apply(lambda x: x // 10)\n",
    "kick_projects['Goal_1000'] = kick_projects.goal.apply(lambda x: x // 1000)\n",
    "kick_projects['Goal_100'] = kick_projects.goal.apply(lambda x: x // 100)\n",
    "kick_projects['Goal_500'] = kick_projects.goal.apply(lambda x: x // 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b9ff90d44cad2193b8e18966382f66819bea372"
   },
   "outputs": [],
   "source": [
    "#features from date column\n",
    "kick_projects['duration']=(kick_projects['deadline_date']-kick_projects['launched_date']).dt.days\n",
    "#the idea for deriving launched quarter month year is that perhaps projects launched in a particular year/ quarter/ month might have a low success rate\n",
    "kick_projects['launched_quarter']= kick_projects['launched_date'].dt.quarter\n",
    "kick_projects['launched_month']= kick_projects['launched_date'].dt.month\n",
    "kick_projects['launched_year']= kick_projects['launched_date'].dt.year\n",
    "kick_projects['launched_week']= kick_projects['launched_date'].dt.week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "837a3baa8aa0dae82ae5033c7302d844b000eed9"
   },
   "outputs": [],
   "source": [
    "#additional features from goal, pledge and backers columns\n",
    "kick_projects.loc[:,'goal_reached'] = kick_projects['pledged'] / kick_projects['goal'] # Pledged amount as a percentage of goal.\n",
    "#The above field will be used to compute another metric\n",
    "# In backers column, impute 0 with 1 to prevent undefined division.\n",
    "kick_projects.loc[kick_projects['backers'] == 0, 'backers'] = 1 \n",
    "kick_projects.loc[:,'pledge_per_backer'] = kick_projects['pledged'] / kick_projects['backers'] # Pledged amount per backer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ea3f2449798864280f007eb7189d740cce69123"
   },
   "outputs": [],
   "source": [
    "#will create percentile buckets for the goal amount in a category\n",
    "kick_projects['goal_cat_perc'] =  kick_projects.groupby(['category'])['goal'].transform(\n",
    "                     lambda x: pd.qcut(x, [0, .35, .70, 1.0], labels =[1,2,3]))\n",
    "\n",
    "#will create percentile buckets for the duration in a category\n",
    "kick_projects['duration_cat_perc'] =  kick_projects.groupby(['category'])['duration'].transform(\n",
    "                     lambda x: pd.qcut(x, [0, .35, .70, 1.0], labels =False, duplicates='drop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b225db33392d67683aa8496fb79d1269e4f7d61"
   },
   "outputs": [],
   "source": [
    "#creating a metric to see number of competitors for a given project in a given quarter\n",
    "#number of participants in a given category, that launched in the same year and quarter and in the same goal bucket\n",
    "ks_particpants_qtr=kick_projects.groupby(['category','launched_year','launched_quarter','goal_cat_perc']).count()\n",
    "ks_particpants_qtr=ks_particpants_qtr[['name']]\n",
    "#since the above table has all group by columns created as index, converting them into columns\n",
    "ks_particpants_qtr.reset_index(inplace=True)\n",
    "\n",
    "#creating a metric to see number of competitors for a given project in a given month\n",
    "#number of participants in a given category, that launched in the same year and month and in the same goal bucket\n",
    "ks_particpants_mth=kick_projects.groupby(['category','launched_year','launched_month','goal_cat_perc']).count()\n",
    "ks_particpants_mth=ks_particpants_mth[['name']]\n",
    "#since the above table has all group by columns created as index, converting them into columns\n",
    "ks_particpants_mth.reset_index(inplace=True)\n",
    "\n",
    "#creating a metric to see number of competitors for a given project in a given week\n",
    "#number of participants in a given category, that launched in the same year and week and in the same goal bucket\n",
    "ks_particpants_wk=kick_projects.groupby(['category','launched_year','launched_week','goal_cat_perc']).count()\n",
    "ks_particpants_wk=ks_particpants_wk[['name']]\n",
    "#since the above table has all group by columns created as index, converting them into columns\n",
    "ks_particpants_wk.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3e4ed868f5a015b1628864cb18974a55c7c45719"
   },
   "outputs": [],
   "source": [
    "#renaming columns of the derived table\n",
    "colmns_qtr=['category', 'launched_year', 'launched_quarter', 'goal_cat_perc', 'participants_qtr']\n",
    "ks_particpants_qtr.columns=colmns_qtr\n",
    "\n",
    "colmns_mth=['category', 'launched_year', 'launched_month', 'goal_cat_perc', 'participants_mth']\n",
    "ks_particpants_mth.columns=colmns_mth\n",
    "\n",
    "colmns_wk=['category', 'launched_year', 'launched_week', 'goal_cat_perc', 'participants_wk']\n",
    "ks_particpants_wk.columns=colmns_wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8489bc88cd825f37ac74e9398c639f062fd7fba6"
   },
   "outputs": [],
   "source": [
    "#merging the particpants column into the base table\n",
    "kick_projects = pd.merge(kick_projects, ks_particpants_qtr, on = ['category', 'launched_year', 'launched_quarter','goal_cat_perc'], how = 'left')\n",
    "kick_projects = pd.merge(kick_projects, ks_particpants_mth, on = ['category', 'launched_year', 'launched_month','goal_cat_perc'], how = 'left')\n",
    "kick_projects = pd.merge(kick_projects, ks_particpants_wk, on = ['category', 'launched_year', 'launched_week','goal_cat_perc'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e093fbe166f5ee625f0b7a2d2a4406bed9deac59"
   },
   "outputs": [],
   "source": [
    "#creating 2 metrics to get average pledge per backer for a category in a year according to the goal bucket it lies in and the success rate ie average pledged to goal ratio for the category and goal bucket in this year\n",
    "#using pledge_per_backer (computed earlier) and averaging it by category in a launch year\n",
    "ks_ppb_goal=pd.DataFrame(kick_projects.groupby(['category','launched_year','goal_cat_perc'])['pledge_per_backer','goal_reached'].mean())\n",
    "#since the above table has all group by columns created as index, converting them into columns\n",
    "ks_ppb_goal.reset_index(inplace=True)\n",
    "#renaming column\n",
    "ks_ppb_goal.columns= ['category','launched_year','goal_cat_perc','avg_ppb_goal','avg_success_rate_goal']\n",
    "\n",
    "#creating a metric: the success rate ie average pledged to goal ratio for the category in this year\n",
    "ks_ppb_duration=pd.DataFrame(kick_projects.groupby(['category','launched_year','duration_cat_perc'])['goal_reached'].mean())\n",
    "#since the above table has all group by columns created as index, converting them into columns\n",
    "ks_ppb_duration.reset_index(inplace=True)\n",
    "#renaming column\n",
    "ks_ppb_duration.columns= ['category','launched_year','duration_cat_perc','avg_success_rate_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "733f7047afab702b56a62e7ef330f33d450e1825"
   },
   "outputs": [],
   "source": [
    "#merging the particpants column into the base table\n",
    "kick_projects = pd.merge(kick_projects, ks_ppb_goal, on = ['category', 'launched_year','goal_cat_perc'], how = 'left')\n",
    "kick_projects = pd.merge(kick_projects, ks_ppb_duration, on = ['category', 'launched_year','duration_cat_perc'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1a6e2cde06e1d1cad7c000c3ffc5852a151510ce"
   },
   "outputs": [],
   "source": [
    "#creating 2 metrics: mean and median goal amount\n",
    "median_goal_cat=pd.DataFrame(kick_projects.groupby(['category','launched_year','duration_cat_perc'])['goal'].median())\n",
    "#since the above table has all group by columns created as index, converting them into columns\n",
    "median_goal_cat.reset_index(inplace=True)\n",
    "#renaming column\n",
    "median_goal_cat.columns= ['category','launched_year','duration_cat_perc','median_goal_year']\n",
    "\n",
    "mean_goal_cat=pd.DataFrame(kick_projects.groupby(['category','launched_year','duration_cat_perc'])['goal'].mean())\n",
    "#since the above table has all group by columns created as index, converting them into columns\n",
    "mean_goal_cat.reset_index(inplace=True)\n",
    "#renaming column\n",
    "mean_goal_cat.columns= ['category','launched_year','duration_cat_perc','mean_goal_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad750790b5c298591a2a43c24b4e7a72f7aaae1a"
   },
   "outputs": [],
   "source": [
    "#merging the particpants column into the base table\n",
    "kick_projects = pd.merge(kick_projects, median_goal_cat, on = ['category', 'launched_year','duration_cat_perc'], how = 'left')\n",
    "kick_projects = pd.merge(kick_projects, mean_goal_cat, on = ['category', 'launched_year','duration_cat_perc'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9d93417fce293d83904a619120a29b9f76e6ee5"
   },
   "outputs": [],
   "source": [
    "print(kick_projects.shape)\n",
    "kick_projects[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd90aa6effcd7d3214e9cffa0bac173867ba341f"
   },
   "outputs": [],
   "source": [
    "# replacing all 'N,0\"' values in the country column with 'NZERO' to avoid discrepancies while one hot encoding\n",
    "kick_projects = kick_projects.replace({'country': 'N,0\"'}, {'country': 'NZERO'}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e9805dac04702df31631c2858f145eb45fab33a2"
   },
   "outputs": [],
   "source": [
    "list(kick_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4de4f4f39895672c6b61d3b898bbf839ba751bf1"
   },
   "outputs": [],
   "source": [
    "#selecting the needed fields only\n",
    "#this will lead to the final features list\n",
    "\n",
    "#creating a list of columns to be dropped\n",
    "drop_columns= ['name','launched','deadline','launched_date','deadline_date','pledged','backers','usd_pledged','usd_pledged_real','pledge_per_backer','goal_reached']\n",
    "#dropping columns above\n",
    "kick_projects.drop(drop_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dbc5c211ab9cf50dfcca0086c58cb42dd4860826"
   },
   "outputs": [],
   "source": [
    "#these functions will be used on the textual column entries to remove '&','-' or white spaces\n",
    "def replace_ampersand(val):\n",
    "    if isinstance(val, str):\n",
    "        return(val.replace('&', 'and'))\n",
    "    else:\n",
    "        return(val)\n",
    "\n",
    "def replace_hyphen(val):\n",
    "    if isinstance(val, str):\n",
    "        return(val.replace('-', '_'))\n",
    "    else:\n",
    "        return(val)    \n",
    "    \n",
    "def remove_extraspace(val):\n",
    "        if isinstance(val, str):\n",
    "            return(val.strip())\n",
    "        else:\n",
    "            return(val) \n",
    "\n",
    "def replace_space(val):\n",
    "        if isinstance(val, str):\n",
    "            return(val.replace(' ', '_'))\n",
    "        else:\n",
    "            return(val)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bdda369b978137ff76ac60204e77bdded576b964"
   },
   "outputs": [],
   "source": [
    "#apply those functions to all cat columns\n",
    "#this will remove special characters from the character columns.\n",
    "#Since these fields will be one-hot encoded, the column names so derived should be compatible with the requied format\n",
    "kick_projects['category'] = kick_projects['category'].apply(remove_extraspace)\n",
    "kick_projects['category'] = kick_projects['category'].apply(replace_ampersand)\n",
    "kick_projects['category'] = kick_projects['category'].apply(replace_hyphen)\n",
    "kick_projects['category'] = kick_projects['category'].apply(replace_space)\n",
    "\n",
    "kick_projects['main_category'] = kick_projects['main_category'].apply(remove_extraspace)\n",
    "kick_projects['main_category'] = kick_projects['main_category'].apply(replace_ampersand)\n",
    "kick_projects['main_category'] = kick_projects['main_category'].apply(replace_hyphen)\n",
    "kick_projects['main_category'] = kick_projects['main_category'].apply(replace_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "030ea50e9a1ecc0bbefb7b03b537e9e15e5265bb"
   },
   "outputs": [],
   "source": [
    "#missing value treatment\n",
    "# Check for nulls.\n",
    "kick_projects.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f650fd1b3060ec8e9da27526eb4fbae49042dc1c"
   },
   "source": [
    "There are only 3 rows with nulls, and the rows with nulls have no names. These rows can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1df9f84243000b01b8a31baba3ffdc8897d44ba1"
   },
   "outputs": [],
   "source": [
    "#dropping all rows that have any nulls\n",
    "kick_projects=kick_projects.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82fbc8cb73fddb3818a55d083f2fa8dd739e0de4"
   },
   "outputs": [],
   "source": [
    "# Check for nulls again.\n",
    "kick_projects.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2f39bd5e599df08a66a2a90bf9e2766313107dfe"
   },
   "source": [
    "No nulls, we are good to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ddc24b47ea6c3742f279a862e0a945305e0583f0"
   },
   "outputs": [],
   "source": [
    "#creating a backup copy of the dataset\n",
    "kick_projects_copy= kick_projects.copy()\n",
    "\n",
    "kick_projects_copy[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f698e3f5dac9d2e6c3aa9e8ffb74fdfbafa10a4"
   },
   "outputs": [],
   "source": [
    "for c in kick_projects.columns:\n",
    "    #this gives us the list of columns and the respective data types\n",
    "    col_type = kick_projects[c].dtype\n",
    "    #looking through all categorical columns in the list above\n",
    "    if col_type == 'object' :\n",
    "        a=kick_projects[c].unique()\n",
    "        keys= range(a.shape[0])\n",
    "        #initiating a dictionary\n",
    "        diction={}\n",
    "        for idx,val in enumerate(a):\n",
    "        #looping through to create the dictionary with mappings\n",
    "            diction[idx] = a[idx]\n",
    "        #the above step maps integers to the values in the column\n",
    "        # hence inverting the key-value pairs\n",
    "        diction = {v: k for k, v in diction.items()}\n",
    "        print(diction)\n",
    "        # creating a dictionary for mapping the values to integers\n",
    "        kick_projects_copy[c] = [diction[item] for item in kick_projects_copy[c]] \n",
    "        # converting data type to 'category'\n",
    "        kick_projects_copy[c] = kick_projects_copy[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1624702e4d33399ea9f22bfb94186510b2b628a5"
   },
   "outputs": [],
   "source": [
    "# One-Hot encoding to convert categorical columns to numeric\n",
    "print('start one-hot encoding')\n",
    "\n",
    "kick_projects_ip = pd.get_dummies(kick_projects, prefix = [ 'category', 'main_category', 'currency','country'],\n",
    "                             columns = [ 'category', 'main_category', 'currency','country'])\n",
    "    \n",
    "#this will have created 1-0 flag columns (like a sparse matrix)    \n",
    "print('ADS dummy columns made')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f55f59fceac8fd7dfdc96c11a7013edf53001784"
   },
   "outputs": [],
   "source": [
    "#creating 2 arrays: features and response\n",
    "\n",
    "#features will have all independent variables\n",
    "features=list(kick_projects_ip)\n",
    "features.remove('state')\n",
    "#response has the target variable\n",
    "response= ['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5800d73f5738e7e2f54fb41e42b849967120c76a"
   },
   "outputs": [],
   "source": [
    "#creating a backup copy of the input dataset\n",
    "kick_projects_ip_copy= kick_projects_ip.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3d577db0d67603a11ea8c76a3f85f7b7db4cabe"
   },
   "outputs": [],
   "source": [
    "kick_projects_ip[features].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db431e0ede0ca45a6b2a471fc674ba7afe04c868"
   },
   "outputs": [],
   "source": [
    "# normalize the data attributes\n",
    "kick_projects_ip_scaled_ftrs = pd.DataFrame(preprocessing.normalize(kick_projects_ip[features]))\n",
    "kick_projects_ip_scaled_ftrs.columns=list(kick_projects_ip[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0064f92ba73f90d19564565e9bdd8bc4cb8950cc"
   },
   "outputs": [],
   "source": [
    "kick_projects_ip_scaled_ftrs[:3]\n",
    "#kick_projects_ip[features].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c36fa9122b2959ac988bf21fa1a5bac9a93a090"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "0be2ac6a4e06d00eb01a6396e1907f59ecf637bc"
   },
   "outputs": [],
   "source": [
    "#creating test and train dependent and independent variables\n",
    "#Split the data into test and train (30-70: random sampling)\n",
    "#will be using the scaled dataset to split \n",
    "train_ind, test_ind, train_dep, test_dep = train_test_split(kick_projects_ip_scaled_ftrs, kick_projects_ip[response], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d206e0f39bc7994e2fbd4783f12ab6b81e08412"
   },
   "source": [
    "### XGBoost classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f151b7de300cd71a1814a31f809d1b965c4aa11"
   },
   "source": [
    "XGBoost is an implementation of gradient boosted decision trees designed which promises speed and performance. The two reasons XGBoost is a good choice of model are: 1.Execution Speed (as compared to decision trees)  2.Model Performance. This algorithm is also known as gradient boosting, multiple additive regression trees, stochastic gradient boosting or gradient boosting machines.\n",
    "\n",
    "The basic concept of Boosting is that it is an ensemble technique where new models are added to correct the errors made by existing models. Models are added sequentially until no further improvements can be made. In Gradient boosting,  new models are created that predict the residuals or errors of prior models and then added together to make the final prediction. It is called so as it uses a gradient descent algorithm to minimize the loss when adding new models. The parameters used to optimize the XGBoost model at every tree is: Logarithmic Loss, or simply Log Loss. It is a classification loss function.\n",
    "\n",
    "Log Loss quantifies the accuracy of a classifier by penalising false classifications based on the probability of assigning that class. Minimising the Log Loss is basically equivalent to maximising the accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6ff3429e381226150fd5b646307975c8bdae00e6"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f0210274a3da03ef9e7164130ecd91e0cb3ab6e2"
   },
   "outputs": [],
   "source": [
    "#def timer(start_time=None):\n",
    "#    if not start_time:\n",
    "#        start_time = datetime.now()\n",
    "#        return start_time\n",
    "#    elif start_time:\n",
    "#        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "#        tmin, tsec = divmod(temp_sec, 60)\n",
    "#        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e1b1b4e01c8e6d452ba1391142b26389de662554"
   },
   "outputs": [],
   "source": [
    "# defining the XGBoost model\n",
    "xgb_model = XGBClassifier(\n",
    " n_estimators= 1200,\n",
    " learning_rate= 0.08,\n",
    " max_depth= 5,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic'\n",
    " )\n",
    "\n",
    "\n",
    "# Tried doing a grid search but commented it out for the amount of time it takes\n",
    "## Defining parameters\n",
    "#n_estimators = [500,1000, 1200]\n",
    "#learning_rate = [0.0001, 0.01,0.1, 0.3]\n",
    "#param_grid = dict(learning_rate=learning_rate, n_estimators=n_estimators)\n",
    "\n",
    "## Starting stratified Kfold\n",
    "#kfold = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\n",
    "#random_search = model_selection.RandomizedSearchCV(xgb_model, param_grid, scoring=\"neg_log_loss\", n_jobs=4, cv=kfold.split(train_ind[features], train_dep[response]), n_iter=12)\n",
    "\n",
    "## fitting the random search\n",
    "#start_time = timer(None)\n",
    "#random_result = random_search.fit(train_ind[features], train_dep[response])\n",
    "#timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e04534dfc0c1f91c505148c4cc4234e4015ee2e1"
   },
   "outputs": [],
   "source": [
    "# model fitting\n",
    "xgb_model=xgb_model.fit(train_ind[features], train_dep[response])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "724c79be2a5746e2c4752f07d3b2e0a823480f25"
   },
   "source": [
    "#### Prediction XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64ed9455c9f9d0b6d0e6580a2885e38f2a4a4f7f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict the on the train_data\n",
    "test_ind[\"Pred_state_XGB_2\"] = xgb_model.predict(test_ind[features])\n",
    "\n",
    "# Predict the on the train_data\n",
    "train_ind[\"Pred_state_XGB_2\"] = xgb_model.predict(train_ind[features])\n",
    "\n",
    "# Predict the on the train_data\n",
    "kick_projects_ip[\"Pred_state_XGB_2\"] = xgb_model.predict(kick_projects_ip_scaled_ftrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e29cc17bff6fee97c98be177509bd298a944a9fb"
   },
   "source": [
    "#### Evaluating XGB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f2fbe29b192f0ecac37664717e00ed1f30a5a24",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (\"Test Accuracy :: \",accuracy_score(test_dep[response], xgb_model.predict(test_ind[features])))\n",
    "print (\"Train Accuracy :: \",accuracy_score(train_dep[response], xgb_model.predict(train_ind[features])))\n",
    "print (\"Complete Accuracy  :: \",accuracy_score(kick_projects_ip[response], xgb_model.predict(kick_projects_ip_scaled_ftrs)))\n",
    "print (\" Confusion matrix of complete data is\", confusion_matrix(kick_projects_ip[response],kick_projects_ip[\"Pred_state_XGB_2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b3f142b0941e1d304d35952700008dd593f6d928"
   },
   "source": [
    "#### Deriving important features for predicting state of kickstarter projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58aaf501abee2ab96efe931fbf943a955d4b6c7f"
   },
   "outputs": [],
   "source": [
    "## Feature importances\n",
    "ftr_imp=zip(features,xgb_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da79d29ee91d66e0c0c44ef0278243677cc008b2"
   },
   "outputs": [],
   "source": [
    "for values in ftr_imp:\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a2ee3c3e7027f4bb820d3b17ecf8f38d28981805"
   },
   "outputs": [],
   "source": [
    "# creating a dataframe\n",
    "feature_imp=pd.DataFrame(list(zip(features,xgb_model.feature_importances_)))\n",
    "column_names= ['features','XGB_imp']\n",
    "feature_imp.columns= column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9857b6c7b7269f417de35bcccce8526c1c5376c9"
   },
   "outputs": [],
   "source": [
    "\n",
    "# sort in descending order of importances\n",
    "feature_imp= feature_imp.sort_values('XGB_imp',ascending=False)\n",
    "feature_imp[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9f712fc0404acc318c0689f7afecd0eb4f31fa08"
   },
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0afd12ba37639a8b1a98fd4a79e0f42c55d68dcb"
   },
   "source": [
    "Algorithms like XGBoost have a tendency to overfit  odels as the models are added sequentially to minimize the log loss. Random Forest makes a good choice to compensate for this overfitting. Random Forest is a supervised learning algorithm that is an ensemble of Decision Trees, often trained with the “bagging” method. In simple words, the bagging method combines learning models to improve the overall performance. The Random forest algorithm builds multiple decision trees and merges them together to get a more accurate and stable prediction.\n",
    "\n",
    "Random Forest gets its name from the fact that it lends an additional randomness to the model, while growing the trees. The algorithm searches for the best feature among a random subset of features, instead of using the most important feature directly to split a node. This results in random splits leading to a better model and also prevents overfitting.\n",
    "\n",
    "It is important to note that the RF algorithm uses only a random subset of the features for splitting a node. The randomness of the trees can be additionally increased using random thresholds for each feature instead of searching for the most optimal thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ecb80b57faf8468b70cb35fece0714e39ceb5ad"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "670aafbfa166cb69bfb46f9642a9a90b621e296d"
   },
   "outputs": [],
   "source": [
    "features_count = train_ind.shape[1]\n",
    "\n",
    "parameters_rf = {'n_estimators':[50], 'max_depth':[20], 'max_features': \n",
    "                     [math.floor(np.sqrt(features_count)), math.floor(features_count/3)]}\n",
    "\n",
    "def random_forest_classifier(features, target):\n",
    "    \"\"\"\n",
    "    To train the random forest classifier with features and target data\n",
    "    :param features:\n",
    "    :param target:\n",
    "    :return: trained random forest classifier\n",
    "    \"\"\"\n",
    "    clf = RandomForestClassifier(n_estimators=50,criterion='gini' ,max_depth=20, max_features=2)\n",
    "    clf.fit(features, target)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bce2d1229fb9653acc4782c94cf88725468df631"
   },
   "outputs": [],
   "source": [
    "trained_model_RF= random_forest_classifier(train_ind[features], train_dep[response])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1532a88aaa09ff4c747fb18770ad8ead88c8451d"
   },
   "source": [
    "#### Predictions using RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6871768b3454e816111f608efdc49a45e051795a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict the on the train_data\n",
    "test_ind[\"Pred_state_RF\"] = trained_model_RF.predict(test_ind[features])\n",
    "\n",
    "# Predict the on the train_data\n",
    "train_ind[\"Pred_state_RF\"] = trained_model_RF.predict(train_ind[features])\n",
    "\n",
    "# Predict the on the train_data\n",
    "kick_projects_ip[\"Pred_state_RF\"] = trained_model_RF.predict(kick_projects_ip_scaled_ftrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "078331da45fac7083db6cfbb604ea5478247f167"
   },
   "source": [
    "#### Accuracies of RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "77ef1e566a88477e8fc2e180efce8c19b47fc692"
   },
   "outputs": [],
   "source": [
    "# Train and Test Accuracy\n",
    "print (\"Train Accuracy :: \", accuracy_score(train_dep[response], trained_model_RF.predict(train_ind[features])))\n",
    "print (\"Test Accuracy  :: \", accuracy_score(test_dep[response], trained_model_RF.predict(test_ind[features])))\n",
    "print (\"Complete Accuracy  :: \", accuracy_score(kick_projects_ip[response], trained_model_RF.predict(kick_projects_ip_scaled_ftrs)))\n",
    "print (\" Confusion matrix of complete data is\", confusion_matrix(kick_projects_ip[response],kick_projects_ip[\"Pred_state_RF\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56cbaf931102192672ce8d2764ba43a5a6afb252"
   },
   "source": [
    "#### Key drivers from Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8a886d272776b1fb1bd84a18d3b022aeaf1f0533"
   },
   "outputs": [],
   "source": [
    "## Feature importances\n",
    "ftr_imp_rf=zip(features,trained_model_RF.feature_importances_)\n",
    "for values in ftr_imp_rf:\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "515e86e8f01fd917be06b396441ac519ea3654f1"
   },
   "outputs": [],
   "source": [
    "feature_imp_RF=pd.DataFrame(list(zip(features,trained_model_RF.feature_importances_)))\n",
    "column_names_RF= ['features','RF_imp']\n",
    "feature_imp_RF.columns= column_names_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86554393c6a1b853e8005d4047750cf2fb57a3fc"
   },
   "outputs": [],
   "source": [
    "feature_imp_RF= feature_imp_RF.sort_values('RF_imp',ascending=False)\n",
    "feature_imp_RF[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "792791cc7879822cd2deae338855a9122c9f4045"
   },
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab9ba903a30e328599a326701f3b216d8e0fe83a"
   },
   "source": [
    "LGBM or LightGBM is yet another gradient boosting framework that uses tree-based learning algorithm. What sets it apart from conventional tree-based algorithms like XGBoost is that it grows trees vertically instead of horizontally splitting them. In other words, it means that LightGBM grows trees leaf-wise while other algorithms grows level-wise or depth-wise. \n",
    "\n",
    "The LGBM model chooses the leaf with maximum delta loss to grow. Thus, in the process of growing the same leaf, a leaf-wise algorithm can reduce more loss than any other level-wise algorithm. This results in better accuracy than most other tree-based learning algorithms. Additionally, as the name suggests, LightGBM is computationally less taxing and has faster execution speeds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ee02fd601777ff514a7892da41e521f19e54a5e"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae42a0cf255c97d8bdae5ed6f864bce8c51c117f"
   },
   "outputs": [],
   "source": [
    "#create LGBM classifier model\n",
    "gbm_model = lgb.LGBMClassifier(\n",
    "        boosting_type= \"dart\",\n",
    "        n_estimators=1300,\n",
    "        learning_rate=0.08,\n",
    "        num_leaves=35,\n",
    "        colsample_bytree=.8,\n",
    "        subsample=.9,\n",
    "        max_depth=9,\n",
    "        reg_alpha=.1,\n",
    "        reg_lambda=.1,\n",
    "        min_split_gain=.01\n",
    ")\n",
    "\n",
    "# LGBM with one-hot encoded features\n",
    "#fit the model on training data\n",
    "gbm_model=gbm_model.fit(train_ind[features], \n",
    "            train_dep[response], \n",
    "              verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "468aa48a034f9f854b26c361e6c085342ac41cd7"
   },
   "source": [
    "#### Predictions using LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9420f52788e129036c145a7cc711580f0123438e"
   },
   "outputs": [],
   "source": [
    "# Predict the on the train_data\n",
    "test_ind[\"Pred_state_LGB\"] = gbm_model.predict(test_ind[features])\n",
    "\n",
    "# Predict the on the train_data\n",
    "train_ind[\"Pred_state_LGB\"] = gbm_model.predict(train_ind[features])\n",
    "\n",
    "# Predict the on the train_data\n",
    "kick_projects_ip[\"Pred_state_LGB\"] = gbm_model.predict(kick_projects_ip_scaled_ftrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a9831f7d5e1f2260789652f3dc56c44e440b4ae"
   },
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "78ed1de5995540c29b22a21d21ddb8b4b1514061"
   },
   "outputs": [],
   "source": [
    "# Train and Test Accuracy\n",
    "print (\"Train Accuracy :: \", accuracy_score(train_dep[response], gbm_model.predict(train_ind[features])))\n",
    "print (\"Test Accuracy  :: \", accuracy_score(test_dep[response], gbm_model.predict(test_ind[features])))\n",
    "print (\"Complete Accuracy  :: \", accuracy_score(kick_projects_ip[response], gbm_model.predict(kick_projects_ip_scaled_ftrs)))\n",
    "print (\" Confusion matrix of complete data is\", confusion_matrix(kick_projects_ip[response],kick_projects_ip[\"Pred_state_LGB\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96f88e11df36b9d3f631a5e7e9366625bc6da9e8"
   },
   "outputs": [],
   "source": [
    "# classification matrix\n",
    "print('\\nClassification metrics')\n",
    "print(classification_report(y_true=test_dep[response], y_pred=test_ind[\"Pred_state_LGB\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "345294fa9798733477061efd095fb221d14cf92a"
   },
   "source": [
    "#### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "513b91cb4f8eb43df7e0cd49c1d3f816662f1312"
   },
   "outputs": [],
   "source": [
    "## Feature importances\n",
    "ftr_imp_lgb=zip(features,gbm_model.feature_importances_)\n",
    "\n",
    "for values in ftr_imp_lgb:\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "504e9e77ba7db7a85eca3081118b07602f834592"
   },
   "outputs": [],
   "source": [
    "feature_imp_lgb=pd.DataFrame(list(zip(features,gbm_model.feature_importances_)))\n",
    "column_names_lgb= ['features','LGB_imp']\n",
    "feature_imp_lgb.columns= column_names_lgb\n",
    "\n",
    "feature_imp_lgb= feature_imp_lgb.sort_values('LGB_imp',ascending=False)\n",
    "feature_imp_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b3158973a60a7767a10ffc63502b9a4b9656621d"
   },
   "source": [
    "### LGBM with categorical level as category columns; no normalization of numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5d212775e3d8b0f6a4a31013f62b7261b3046fe"
   },
   "source": [
    "Let us call this one LGB2 model for easy reference later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c8befc36711438f8bf59da1585637894b501ba2b"
   },
   "source": [
    "Doing this exercise with LGBM again, but without one-hot encoding the categorical features. Instead, I have assigned an integer value to each of the 'category', 'main_category', 'currency' and 'country' values. This will then be passed as category columns to LGBM using the 'categorical_feature' argument of the LGBMClassifier.fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "94484d41488a093d374c106eb1829e8dbc6e875b"
   },
   "outputs": [],
   "source": [
    "#creating features and response list\n",
    "features_2=list(kick_projects_copy)\n",
    "features_2.remove('state')\n",
    "features_2_numerical = [e for e in features_2 if e not in ('category','main_category','country','currency')]\n",
    "features_2_categorical = ['category','main_category','country','currency']\n",
    "response = ['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5cfe3d7edbb1b80ab124c1e6cf6cc03608b844c"
   },
   "outputs": [],
   "source": [
    "# Assuming same lines from your example\n",
    "cols_to_norm = features_2_numerical\n",
    "kick_projects_copy[cols_to_norm] = kick_projects_copy[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a6c98c77b02395f55d7b54f573f8faeb2c02f0d"
   },
   "outputs": [],
   "source": [
    "#creating test and train dependent and independent variables\n",
    "#Split the data into test and train (30-70: random sampling)\n",
    "#will be using the scaled dataset to split \n",
    "train_ind_2, test_ind_2, train_dep_2, test_dep_2 = train_test_split(kick_projects_copy[features_2],kick_projects_copy[response], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "745a7a113577314d586bb4caf1f95d9ee15ee56e"
   },
   "outputs": [],
   "source": [
    "#create LGBM classifier model\n",
    "gbm_model_2 = lgb.LGBMClassifier(\n",
    "        boosting_type= \"dart\",\n",
    "        n_estimators=1500,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=38,\n",
    "        colsample_bytree=.8,\n",
    "        subsample=.9,\n",
    "        max_depth=9,\n",
    "        reg_alpha=.1,\n",
    "        reg_lambda=.1,\n",
    "        min_split_gain=.01\n",
    ")\n",
    "\n",
    "# LGBM with one-hot encoded features\n",
    "#fit the model on training data\n",
    "gbm_model_2=gbm_model_2.fit(train_ind_2[features_2], \n",
    "            train_dep_2[response], \n",
    "            feature_name=features_2,\n",
    "            categorical_feature= features_2_categorical,                \n",
    "              verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "35a12e82cdd50260664a7b9e1c48a576b0f78a26"
   },
   "source": [
    "#### Predictions using LGBM (version 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "08b9c4f7011cd5cd9045fdfc6ecd1261fb683a4f"
   },
   "outputs": [],
   "source": [
    "# Predict the on the train_data\n",
    "test_ind_2[\"Pred_state_LGB\"] = gbm_model_2.predict(test_ind_2[features_2])\n",
    "\n",
    "# Predict the on the train_data\n",
    "train_ind_2[\"Pred_state_LGB\"] = gbm_model_2.predict(train_ind_2[features_2])\n",
    "\n",
    "# Predict the on the train_data\n",
    "kick_projects_copy[\"Pred_state_LGB\"] = gbm_model_2.predict(kick_projects_copy[features_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "013f6e34f34d40179cd2f7da31e2af59d7e07a85"
   },
   "source": [
    "#### Evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7bfd2aa1e123e1a848852c13a4377f9edc97439"
   },
   "outputs": [],
   "source": [
    "# Train and Test Accuracy\n",
    "print (\"Train Accuracy :: \", accuracy_score(train_dep_2[response], gbm_model_2.predict(train_ind_2[features_2])))\n",
    "print (\"Test Accuracy  :: \", accuracy_score(test_dep_2[response], gbm_model_2.predict(test_ind_2[features_2])))\n",
    "print (\"Complete Accuracy  :: \", accuracy_score(kick_projects_copy[response], gbm_model_2.predict(kick_projects_copy[features_2])))\n",
    "print (\" Confusion matrix of complete data is\", confusion_matrix(kick_projects_copy[response],kick_projects_copy[\"Pred_state_LGB\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a451e954630ae2b96fdef46254e4fd5ca221426"
   },
   "outputs": [],
   "source": [
    "# classification matrix\n",
    "print('\\nClassification metrics')\n",
    "print(classification_report(y_true=test_dep_2[response], y_pred=gbm_model_2.predict(test_ind_2[features_2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e68b04aaebdea519a9b30e4471f64552610c4708"
   },
   "source": [
    "#### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "87e9407da0f708277d03de348190d4e964adf7bc"
   },
   "outputs": [],
   "source": [
    "## Feature importances\n",
    "ftr_imp_lgb_2=zip(features_2,gbm_model_2.feature_importances_)\n",
    "\n",
    "for values in ftr_imp_lgb_2:\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36211475bf15e24d90440508bbb93917831098ea"
   },
   "outputs": [],
   "source": [
    "# creating a dataframe to get top features\n",
    "feature_imp_lgb_2=pd.DataFrame(list(zip(features_2,gbm_model_2.feature_importances_)))\n",
    "column_names_lgb_2= ['features','LGB_imp_2']\n",
    "feature_imp_lgb_2.columns= column_names_lgb_2\n",
    "\n",
    "feature_imp_lgb_2= feature_imp_lgb_2.sort_values('LGB_imp_2',ascending=False)\n",
    "feature_imp_lgb_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c2857fea278ea61171674d1702a9878e9e8babb"
   },
   "source": [
    "Since we see category is coming out to be abnormally high in importance, treating it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39d8fd8ac0af3c206683ad133beefc6b1995b13f"
   },
   "outputs": [],
   "source": [
    "class LGBMClassifier_GainFE(lgb.LGBMClassifier):\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        if self._n_features is None:\n",
    "            raise LGBMNotFittedError('No feature_importances found. Need to call fit beforehand.')\n",
    "        return self.booster_.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "65110f3ddedf056d480b7d026d5c81dd7d00e148"
   },
   "outputs": [],
   "source": [
    "# defining parameters\n",
    "lgb_gain = LGBMClassifier_GainFE(boosting_type= \"dart\",\n",
    "        n_estimators=1500,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=38,\n",
    "        colsample_bytree=.8,\n",
    "        subsample=.9,\n",
    "        max_depth=9,\n",
    "        reg_alpha=.1,\n",
    "        reg_lambda=.1,\n",
    "        min_split_gain=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "817cc91046c491d170c7b8f21ae8327e1eefb824",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fitting the model\n",
    "lgb_gain.fit(train_ind_2[features_2], \n",
    "            train_dep_2[response], \n",
    "            feature_name=features_2,\n",
    "            categorical_feature= features_2_categorical,                \n",
    "              verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb2961da91d332cbe9c87c6382e80a9b48dc12e7"
   },
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03e3a2cb65d2f81f77476dd8e829ac0fc69efce5"
   },
   "outputs": [],
   "source": [
    "# Predict the on the train_data\n",
    "test_ind_2[\"Pred_state_LGB_Gain\"] = lgb_gain.predict(test_ind_2[features_2])\n",
    "\n",
    "# Predict the on the train_data\n",
    "train_ind_2[\"Pred_state_LGB_Gain\"] = lgb_gain.predict(train_ind_2[features_2])\n",
    "\n",
    "# Predict the on the train_data\n",
    "kick_projects_copy[\"Pred_state_LGB_Gain\"] = lgb_gain.predict(kick_projects_copy[features_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "350a39a513c533ea172e6aeb4896300e968203a2"
   },
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f857f695dd10cc934317383c17ceb9d476a1c660"
   },
   "outputs": [],
   "source": [
    "# Train and Test Accuracy\n",
    "print (\"Train Accuracy :: \", accuracy_score(train_dep_2[response], lgb_gain.predict(train_ind_2[features_2])))\n",
    "print (\"Test Accuracy  :: \", accuracy_score(test_dep_2[response], lgb_gain.predict(test_ind_2[features_2])))\n",
    "print (\"Complete Accuracy  :: \", accuracy_score(kick_projects_copy[response], lgb_gain.predict(kick_projects_copy[features_2])))\n",
    "print (\" Confusion matrix of complete data is\", confusion_matrix(kick_projects_copy[response],kick_projects_copy[\"Pred_state_LGB_Gain\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a334dab56ff80a4a300befaa101f07b57d1bc59a"
   },
   "source": [
    "#### Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3e02a6f88d92eee0a4ec6b11f0f70dda8d4a171"
   },
   "outputs": [],
   "source": [
    "## Feature importances\n",
    "ftr_imp_lgb_gain=zip(features_2,lgb_gain.feature_importances_)\n",
    "\n",
    "for values in ftr_imp_lgb_gain:\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96274f86c7e5fffe35b001eb89233aa8d44e221d"
   },
   "outputs": [],
   "source": [
    "# creating a dataframe to get top 15 features\n",
    "ftr_imp_lgb_gain=pd.DataFrame(list(zip(features_2,lgb_gain.feature_importances_)))\n",
    "column_names_lgb_gain= ['features','LGB_gain_imp']\n",
    "ftr_imp_lgb_gain.columns= column_names_lgb_gain\n",
    "\n",
    "ftr_imp_lgb_gain= ftr_imp_lgb_gain.sort_values('LGB_gain_imp',ascending=False)\n",
    "ftr_imp_lgb_gain[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2cf3818c40f46b66327069f8b6912aa8e3a14c96"
   },
   "source": [
    "This still gives a similar feature list. Category is still the most important feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e27df719f8470b67497ba507e2213750b29fcd81"
   },
   "source": [
    "## Ensemble Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f9ac8e453ca0bef423a688894a09d4b5d9546cf9"
   },
   "source": [
    "### Simple Ensemble: Average Probabailities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3885bc6df5352e4ca5504ced7e96dfcb7c099533"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76897ccf408ff78d27c7913d93f1ad6636934c8c"
   },
   "outputs": [],
   "source": [
    "#creating 4 models for ensembling: Decision Tree (using gini and entropy), knn and Logistic Regression\n",
    "model_dtc_g = tree.DecisionTreeClassifier()\n",
    "model_dtc_e = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "model_knn = neighbors.KNeighborsClassifier()\n",
    "model_lr= LogisticRegression(penalty='l1',solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "336af42d4d78dee53f7203afdc8c9f3521da22c9"
   },
   "outputs": [],
   "source": [
    "#fitting each of the model above\n",
    "model_dtc_g.fit(train_ind[features], train_dep[response])\n",
    "model_dtc_e.fit(train_ind[features], train_dep[response])\n",
    "model_knn.fit(train_ind[features], train_dep[response])\n",
    "model_lr.fit(train_ind[features], train_dep[response])\n",
    "\n",
    "#predicting the probabilities\n",
    "pred_dtc_g=model_dtc_g.predict_proba(test_ind[features])\n",
    "pred_dtc_e=model_dtc_e.predict_proba(test_ind[features])\n",
    "pred_knn=model_knn.predict_proba(test_ind[features])\n",
    "pred_lr=model_lr.predict_proba(test_ind[features])\n",
    "\n",
    "#averaging the 4 predictions above\n",
    "finalpred=(pred_dtc_g+pred_dtc_e+pred_knn+pred_lr)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2768a0ee452df7d4dda837dcfc0e6b94a1427722"
   },
   "outputs": [],
   "source": [
    "#creating the dataframe with predicted probabilities (for 0 and 1)\n",
    "pred_proba_avg=pd.DataFrame(finalpred)\n",
    "#the results have 2 probabilities: prob of the state being 0 and state being 1 in that order: hence the 2 columns\n",
    "col_names=['prob_0','prob_1']\n",
    "pred_proba_avg.columns=col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a18ab0c25c05180c4a8dff22d093b8634d0bdead"
   },
   "outputs": [],
   "source": [
    "# if the probability of 0> probability of 1: state is 0 and vice versa\n",
    "def final_state(c):\n",
    "    if c['prob_0'] >c['prob_1']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "#creating the final predicted state column using the averaging method    \n",
    "pred_proba_avg['final_state_avg'] = pred_proba_avg.apply(final_state, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7bcff7e65e8ea0190cd1b43a96eaee1d1f68c5df"
   },
   "outputs": [],
   "source": [
    "#appending to base dataframe\n",
    "test_ind = test_ind.reset_index(drop=True)\n",
    "pred_proba_avg = pred_proba_avg.reset_index(drop=True)\n",
    "test_ind=pd.concat([test_ind,pred_proba_avg],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e431c469e9301865763f0aa0f282dc72f875e26b"
   },
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31372e04eec3a1e1165128e81b67185a24e14adf"
   },
   "outputs": [],
   "source": [
    "print (\"Test Accuracy  :: \", accuracy_score(test_dep[response],test_ind['final_state_avg']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be2fb41eb876eb3f65c3b7236d4285fcf4b06542"
   },
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad8263a89418f5cb073710f8c49357afdf5185b0"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b9cf55a96ff077d4825448cc5822ac66c174fcc1"
   },
   "outputs": [],
   "source": [
    "#creating the ADA Boost classifier using XGBoost\n",
    "model_ada = AdaBoostClassifier(random_state=1)\n",
    "model_ada.fit(train_ind[features], train_dep[response])\n",
    "\n",
    "#accuracy score\n",
    "model_ada.score(test_ind[features],test_dep[response])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
